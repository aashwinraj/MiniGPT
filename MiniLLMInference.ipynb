{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a898f7d-72c7-44ea-a5d7-cf8a63c95ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "checkpoint_dir = \"checkpoint_epoch_3\"  # change to your folder name\n",
    "checkpoint = torch.load(os.path.join(checkpoint_dir, \"model.pt\"), map_location=device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_dir)\n",
    "BLOCK_SIZE=256\n",
    "VOCAB_SIZE=len(tokenizer)\n",
    "BLOCK_SIZE=256\n",
    "D_MODEL=512\n",
    "N_HEADS=16\n",
    "N_LAYERS=16\n",
    "DFF=4*512\n",
    "class CausalLM(nn.Module):\n",
    "    def __init__(self,n_head,d_model,dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model=d_model\n",
    "        self.n_head=n_head\n",
    "        self.dk=d_model//n_head\n",
    "        self.qkv=nn.Linear(d_model,3*d_model,bias=False)\n",
    "        self.out_proj=nn.Linear(d_model,d_model,bias=False)\n",
    "        self.proj_dropout=nn.Dropout(dropout)\n",
    "        self.attn_dropout=nn.Dropout(dropout)\n",
    "    def build_causal_mask(self,T,device):\n",
    "        mask = torch.tril(torch.ones((T, T), dtype=torch.bool, device=device))\n",
    "        # we'll use it to set -inf on disallowed positions\n",
    "        return mask.unsqueeze(0).unsqueeze(0)\n",
    "    def forward(self,x):\n",
    "        B,T,D=x.shape\n",
    "        qkv=self.qkv(x)\n",
    "        q,k,v=qkv.chunk(3,-1)\n",
    "        q=q.view(B,T,self.n_head,self.dk).transpose(1,2)\n",
    "        k=k.view(B,T,self.n_head,self.dk).transpose(1,2)\n",
    "        v=v.view(B,T,self.n_head,self.dk).transpose(1,2)\n",
    "        scores=torch.matmul(q,k.transpose(-2,-1))\n",
    "        scores=scores/(self.dk**0.5)\n",
    "        self.causal_mask=self.build_causal_mask(T,x.device)\n",
    "        causal=self.causal_mask[:,:,:T,:T]\n",
    "        scores = scores.masked_fill(~causal, float(\"-inf\"))\n",
    "        attn_weights=f.softmax(scores,dim=-1)\n",
    "        attn_weights=self.attn_dropout(attn_weights)\n",
    "        context=torch.matmul(attn_weights,v)\n",
    "        context=context.transpose(1,2).contiguous().view(B,T,D)\n",
    "        out=self.out_proj(context)\n",
    "        out=self.proj_dropout(out)\n",
    "        return out\n",
    "        \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,ff_dim,d_model,dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.net=nn.Sequential(nn.Linear(d_model,ff_dim),\n",
    "                               nn.GELU(),\n",
    "                               nn.Linear(ff_dim,d_model),\n",
    "                               nn.Dropout(dropout)\n",
    "                              )\n",
    "    def forward(self,x):\n",
    "        return self.net(x)    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,d_model,n_heads,dff,dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.ln1=nn.LayerNorm(d_model)\n",
    "        self.attn=CausalLM(n_heads,d_model)\n",
    "        self.ln2=nn.LayerNorm(d_model)\n",
    "        self.ff=FeedForward(dff,d_model,dropout)\n",
    "    def forward(self,x):\n",
    "        x=x+self.attn(self.ln1(x))\n",
    "        x=x+self.ff(self.ln2(x))\n",
    "        return x\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self,vocab_size,block_size,d_model,n_head,n_layers):\n",
    "        super().__init__()\n",
    "        self.token_emb=nn.Embedding(vocab_size,d_model)\n",
    "        self.pos_emb=nn.Embedding(block_size,d_model)\n",
    "        self.blocks=nn.ModuleList([\n",
    "            TransformerBlock(d_model,n_head,dff=4*d_model)\n",
    "        ])\n",
    "        self.lnf=nn.LayerNorm(d_model)\n",
    "        self.head=nn.Linear(d_model,vocab_size,bias=False)\n",
    "        self.block_size=block_size\n",
    "        self.vocab_size=vocab_size\n",
    "    def forward(self,idx,targets=None):\n",
    "        B,T=idx.shape\n",
    "        token_emb=self.token_emb(idx)\n",
    "        pos=torch.arange(T,device=idx.device)\n",
    "        pos_emb=self.pos_emb(pos)\n",
    "        x=token_emb+pos_emb\n",
    "        for block in self.blocks:\n",
    "            x = block(x)                                           # apply transformer block\n",
    "        x = self.lnf(x)                                           # final norm\n",
    "        logits = self.head(x) \n",
    "        if targets!=None:\n",
    "            loss = f.cross_entropy(logits.view(-1, self.vocab_size), targets.view(-1))\n",
    "            return logits, loss\n",
    "        else:\n",
    "            return logits,0\n",
    "model = GPT(VOCAB_SIZE, BLOCK_SIZE, D_MODEL, N_HEADS, N_LAYERS)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "def generate_text(prompt, max_new_tokens=50):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Encode prompt → token IDs\n",
    "        input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Feed only recent tokens (truncate to model's max length)\n",
    "            logits = model(input_ids).logits\n",
    "            logits = logits[:, -1, :]  # last token’s logits\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_id = torch.multinomial(probs, num_samples=1)\n",
    "            input_ids = torch.cat([input_ids, next_id], dim=1)\n",
    "\n",
    "        # Decode back to text\n",
    "        return tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "app = FastAPI(title=\"MiniGPT API\", version=\"1.0\")\n",
    "class GenerateRequest(BaseModel):\n",
    "    prompt: str\n",
    "    max_new_tokens: int = 50\n",
    "@app.post(\"/generate\")\n",
    "async def generate(req: GenerateRequest):\n",
    "    output = generate_text(req.prompt, req.max_new_tokens)\n",
    "    return {\"prompt\": req.prompt, \"generated\": output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d9e9273-2c0c-4383-a839-44bf4d62e8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6f190b7-d3d7-4153-98be-7334f248c330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09b74c2c-1020-4147-af86-4b9ea4426b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (token_emb): Embedding(50257, 512)\n",
       "  (pos_emb): Embedding(256, 512)\n",
       "  (blocks): ModuleList(\n",
       "    (0): TransformerBlock(\n",
       "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalLM(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lnf): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): Linear(in_features=512, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78fc450e-d43c-4f36-ab61-bf2adee59761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a562ec44-330e-4b03-8d45-02faceb7628d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in c:\\programdata\\anaconda3\\lib\\site-packages (25.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 1.6/1.8 MB 12.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 11.5 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "Successfully installed pip-25.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts pip.exe, pip3.13.exe and pip3.exe are installed in 'C:\\Users\\aashw\\AppData\\Roaming\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdd8c8f0-d92b-42b5-90c6-e7bebc4b5864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script uvicorn.exe is installed in 'C:\\Users\\aashw\\AppData\\Roaming\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script fastapi.exe is installed in 'C:\\Users\\aashw\\AppData\\Roaming\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.121.0-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: pydantic in c:\\programdata\\anaconda3\\lib\\site-packages (2.10.3)\n",
      "Collecting starlette<0.50.0,>=0.40.0 (from fastapi)\n",
      "  Downloading starlette-0.49.3-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from fastapi) (4.12.2)\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi)\n",
      "  Downloading annotated_doc-0.0.3-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic) (2.27.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from starlette<0.50.0,>=0.40.0->fastapi) (4.7.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.50.0,>=0.40.0->fastapi) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.50.0,>=0.40.0->fastapi) (1.3.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from uvicorn) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from uvicorn) (0.16.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Downloading fastapi-0.121.0-py3-none-any.whl (109 kB)\n",
      "Downloading starlette-0.49.3-py3-none-any.whl (74 kB)\n",
      "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Downloading annotated_doc-0.0.3-py3-none-any.whl (5.5 kB)\n",
      "Installing collected packages: annotated-doc, uvicorn, starlette, fastapi\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [uvicorn]\n",
      "   ---------- ----------------------------- 1/4 [uvicorn]\n",
      "   ---------- ----------------------------- 1/4 [uvicorn]\n",
      "   ---------- ----------------------------- 1/4 [uvicorn]\n",
      "   -------------------- ------------------- 2/4 [starlette]\n",
      "   -------------------- ------------------- 2/4 [starlette]\n",
      "   -------------------- ------------------- 2/4 [starlette]\n",
      "   -------------------- ------------------- 2/4 [starlette]\n",
      "   -------------------- ------------------- 2/4 [starlette]\n",
      "   -------------------- ------------------- 2/4 [starlette]\n",
      "   -------------------- ------------------- 2/4 [starlette]\n",
      "   -------------------- ------------------- 2/4 [starlette]\n",
      "   ------------------------------ --------- 3/4 [fastapi]\n",
      "   ------------------------------ --------- 3/4 [fastapi]\n",
      "   ------------------------------ --------- 3/4 [fastapi]\n",
      "   ------------------------------ --------- 3/4 [fastapi]\n",
      "   ------------------------------ --------- 3/4 [fastapi]\n",
      "   ------------------------------ --------- 3/4 [fastapi]\n",
      "   ------------------------------ --------- 3/4 [fastapi]\n",
      "   ------------------------------ --------- 3/4 [fastapi]\n",
      "   ------------------------------ --------- 3/4 [fastapi]\n",
      "   ---------------------------------------- 4/4 [fastapi]\n",
      "\n",
      "Successfully installed annotated-doc-0.0.3 fastapi-0.121.0 starlette-0.49.3 uvicorn-0.38.0\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install fastapi uvicorn pydantic\n",
    "\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5c6ee02-dfee-499d-80d2-b53766f92067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f02dc41-406b-4fa8-b682-bfadc1752bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdacdd5b-7afd-49dd-b5b4-22b0a7eaf005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
